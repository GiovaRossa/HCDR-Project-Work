{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "551ce207-0976-48c3-9242-fac3e6bdf527",
    "_uuid": "66406036d8dd7a0071295d1aee64f13bffc44e3a"
   },
   "source": [
    "# Some feature engineering (part I)\n",
    "\n",
    "Kaggle competitions are won by **feature engineering**: those who win are those who can create the most useful features out of the data. This is true for the most part as the winning models, at least for structured data, all tend to be variants of [gradient boosting](http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/). \n",
    "\n",
    "This represents one of the patterns in machine learning: feature engineering has a **greater return on investment** than model building and hyperparameter tuning. As Andrew Ng is fond of saying: \"applied machine learning is basically feature engineering.\"\n",
    "\n",
    "While choosing the right model and optimal settings are important, the **model can only learn from the data it is given**. Making sure this data is as relevant to the task as possible is the job of the data scientist (and maybe some [automated tools](https://docs.featuretools.com/getting_started/install.html) to help us out).\n",
    "\n",
    "Feature engineering refers to a general process and can involve both **feature construction**, i.e., _adding new features from the existing data_, and **feature selection**, i.e., _choosing only the most important features or other methods of dimensionality reduction_. There are many techniques we can use to both create features and select features.\n",
    "\n",
    "We'll start by trying out two simple feature construction methods:\n",
    "\n",
    "- Domain knowledge features\n",
    "- Polynomial features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d632b08c-d252-4238-b496-e2c6edebec4b",
    "_uuid": "eb13bf76d4e1e60d0703856ec391cdc2c5bdf1fb"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's deifne some auxiliary function definitions we'll use later on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def label_encode(app_train, app_test) : \n",
    "    le = LabelEncoder()\n",
    "    le_count = 0\n",
    "\n",
    "    # Iterate through the columns\n",
    "    for col in app_train:\n",
    "        if app_train[col].dtype == 'object':\n",
    "            # If 2 or fewer unique categories\n",
    "            set_values = app_train[col].unique()\n",
    "            num_values = len(list(set_values))\n",
    "            if num_values <= 2:\n",
    "                print(f\"{col} will be label encoded! Found {num_values} values: {set_values}\")\n",
    "                # Train on the training data\n",
    "                le.fit(app_train[col])\n",
    "                # Transform both training and testing data\n",
    "                app_train[col] = le.transform(app_train[col])\n",
    "                app_test[col] = le.transform(app_test[col])\n",
    "\n",
    "                # Keep track of how many columns were label encoded\n",
    "                le_count += 1\n",
    "\n",
    "    print('%d columns were label encoded.' % le_count)\n",
    "    print('Training Features shape: ', app_train.shape)\n",
    "    print('Testing Features shape: ', app_test.shape)\n",
    "    \n",
    "    return app_train, app_test\n",
    "\n",
    "\n",
    "def one_hot_encode(app_train, app_test) :\n",
    "    \n",
    "    # Let's perform the one-hot encoding of categorical features with > 2 values...\n",
    "    app_train = pd.get_dummies(app_train)\n",
    "    app_test = pd.get_dummies(app_test)\n",
    "    print('Training Features shape: ', app_train.shape)\n",
    "    print('Testing Features shape: ', app_test.shape)\n",
    "    \n",
    "    return app_train, app_test\n",
    "\n",
    "\n",
    "def align_train_test(app_train, app_test) :\n",
    "    \n",
    "    # Save target variable in a separate Series...\n",
    "    train_labels = app_train['TARGET']\n",
    "\n",
    "    # Align the training and testing data on columns -- this keeps only the columns present in both dataframes.\n",
    "    app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n",
    "\n",
    "    # Add the target column back in.\n",
    "    app_train['TARGET'] = train_labels\n",
    "    \n",
    "    return train_labels, app_train, app_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "\n",
    "def classify(app_train, app_test, classifier = 'logistic', cv = 5, param_grid = {}, n_jobs = 1) :\n",
    "    \n",
    "    # Pick the classifier desired by the user...\n",
    "    log_reg = LogisticRegression\n",
    "    if classifier == 'decision' : log_reg = DecisionTreeClassifier\n",
    "    elif classifier == 'SVC' : log_reg = SVC\n",
    "    elif classifier == 'rf' : log_reg = RandomForestClassifier\n",
    "    elif classifier == 'lgbm' : log_reg = LGBMClassifier\n",
    "    else : pass\n",
    "    \n",
    "    \n",
    "    # Label encoding, one hot encoding, train-test alignment.\n",
    "    app_train, app_test = label_encode(app_train, app_test)\n",
    "    app_train, app_test = one_hot_encode(app_train, app_test)\n",
    "    train_labels, app_train, app_test = align_train_test(app_train, app_test)\n",
    "    \n",
    "    \n",
    "    train = app_train.drop(columns = ['TARGET'], errors = 'ignore')\n",
    "    test = app_test.copy()\n",
    "    \n",
    " \n",
    "    # Setup the pipeline. \n",
    "    from sklearn.pipeline import Pipeline\n",
    "    clf = Pipeline([('imp', SimpleImputer(strategy = 'median')),\n",
    "                    ('sca', MinMaxScaler(feature_range = (0, 1))),\n",
    "                    ('clf', log_reg(class_weight = 'balanced'))],\n",
    "                    verbose = True)\n",
    "    \n",
    "\n",
    "    # Setup the grid search. \n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    search = GridSearchCV(estimator = clf, \n",
    "                          param_grid = param_grid, \n",
    "                          cv = cv,\n",
    "                          scoring = 'roc_auc',\n",
    "                          n_jobs = n_jobs,\n",
    "                          verbose = 1)\n",
    "    \n",
    "    \n",
    "    # Training ...\n",
    "    search.fit(train, train_labels)\n",
    "\n",
    "    \n",
    "    #print('Miscellanea of results:', search.cv_results_)\n",
    "    #print('Score achieved by the best config. during stratified CV:', search.best_score_)\n",
    "    #print('Best estimator config:', search.best_estimator_)\n",
    "\n",
    "    \n",
    "    # Compute predictions...\n",
    "    log_reg_pred = search.predict_proba(test)[:, 1]\n",
    "    # print(log_reg_pred)\n",
    "\n",
    "    \n",
    "    # Final result dataframe.\n",
    "    submit = app_test[['SK_ID_CURR']]\n",
    "    submit['TARGET'] = log_reg_pred\n",
    "    #submit.head()\n",
    "\n",
    "    \n",
    "    # Compute feature importance (if applicable).\n",
    "    feat_imp = pd.Series(0, index=train.columns)\n",
    "    if(classifier in ['rf', 'lgbm']) :\n",
    "        feat_imp = pd.Series(search.best_estimator_.named_steps[\"clf\"].feature_importances_, index=train.columns)\n",
    "        \n",
    "    # Return the results.\n",
    "    return submit, search.cv_results_, feat_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a5e67831-4751-4f11-8e07-527e3e092671",
    "_uuid": "ded520f73b9e94ed47ac2e994a5fb1bcb9093d0f"
   },
   "source": [
    "## Read in Data \n",
    "\n",
    "First, we can list all the available data files. There are a total of 9 files: 1 main file for training (with target) 1 main file for testing (without the target), 1 example submission file, and 6 other files containing additional information about each loan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Training data\n",
    "app_train = pd.read_csv('./input/application_train.csv')\n",
    "app_test = pd.read_csv('./input/application_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Knowledge Features\n",
    "\n",
    "Maybe it's not entirely correct to call this \"domain knowledge\" because I'm not a credit expert, but perhaps we could call this \"attempts at applying limited financial knowledge\". In this frame of mind, we can make a couple features that attempt to capture what we think may be important to predict whether a client will default on a loan. \n",
    "\n",
    "Here we're going to use four features that were inspired by [this script](https://www.kaggle.com/jsaguiar/updated-0-792-lb-lightgbm-with-simple-features) by Aguiar:\n",
    "\n",
    "* `CREDIT_INCOME_PERCENT`: the percentage of the credit amount relative to a client's income\n",
    "* `ANNUITY_INCOME_PERCENT`: the percentage of the loan annuity relative to a client's income\n",
    "* `CREDIT_TERM`:  the length of the payment in months (since the annuity is the monthly amount due)\n",
    "* `DAYS_EMPLOYED_PERCENT`: the percentage of the days employed relative to the client's age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's copy the dataframes into two new variables...\n",
    "app_train_domain = app_train.copy()\n",
    "app_test_domain = app_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then generate the four features mentioned above. Notice how we create them both in the training set AND in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train_domain['CREDIT_INCOME_PERCENT'] = app_train_domain['AMT_CREDIT'] / app_train_domain['AMT_INCOME_TOTAL']\n",
    "app_train_domain['ANNUITY_INCOME_PERCENT'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_INCOME_TOTAL']\n",
    "app_train_domain['CREDIT_TERM'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_CREDIT']\n",
    "app_train_domain['DAYS_EMPLOYED_PERCENT'] = app_train_domain['DAYS_EMPLOYED'] / app_train_domain['DAYS_BIRTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_test_domain['CREDIT_INCOME_PERCENT'] = app_test_domain['AMT_CREDIT'] / app_test_domain['AMT_INCOME_TOTAL']\n",
    "app_test_domain['ANNUITY_INCOME_PERCENT'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_INCOME_TOTAL']\n",
    "app_test_domain['CREDIT_TERM'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_CREDIT']\n",
    "app_test_domain['DAYS_EMPLOYED_PERCENT'] = app_test_domain['DAYS_EMPLOYED'] / app_test_domain['DAYS_BIRTH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize New Variables\n",
    "\n",
    "We should explore these __domain knowledge__ variables visually in a graph. For all of these, we will make the same KDE plot colored by the value of the `TARGET`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 20))\n",
    "# iterate through the new features\n",
    "for i, feature in enumerate(['CREDIT_INCOME_PERCENT', 'ANNUITY_INCOME_PERCENT', 'CREDIT_TERM', 'DAYS_EMPLOYED_PERCENT']):\n",
    "    \n",
    "    # create a new subplot for each source\n",
    "    plt.subplot(4, 1, i + 1)\n",
    "    # plot repaid loans\n",
    "    sns.kdeplot(app_train_domain.loc[app_train_domain['TARGET'] == 0, feature], label = 'target == 0')\n",
    "    # plot loans that were not repaid\n",
    "    sns.kdeplot(app_train_domain.loc[app_train_domain['TARGET'] == 1, feature], label = 'target == 1')\n",
    "    \n",
    "    # Label the plots\n",
    "    plt.title('Distribution of %s by Target Value' % feature)\n",
    "    plt.xlabel('%s' % feature); plt.ylabel('Density');\n",
    "    \n",
    "plt.tight_layout(h_pad = 2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to say ahead of time if these new features will be useful. The only way to tell for sure is to try them out! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_log = {'clf__C': [0.0001, 0.0005]}\n",
    "param_grid_tree = {'clf__max_depth': [5, 7, 10]}\n",
    "param_grid_rf = {'clf__n_estimators': [150], 'clf__max_depth': [7, 10], 'clf__n_jobs' : [-1]}\n",
    "param_grid_lgbm = {'clf__objective': ['binary'],\n",
    "                   'clf__metric': ['auc'],\n",
    "                   'clf__n_estimators': [150], \n",
    "                   'clf__max_depth': [7, 10]}\n",
    "\n",
    "predictions, search_res, feat_imp_domain = classify(app_train_domain.copy(),\n",
    "                                      app_test_domain.copy(),\n",
    "                                      classifier = 'rf', \n",
    "                                      cv = 3, \n",
    "                                      param_grid = param_grid_rf,\n",
    "                                      n_jobs = 1)\n",
    "\n",
    "for par, score in zip(search_res['params'], search_res['mean_test_score']) :\n",
    "    print(f\"Config: {par} -- score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train our classifier **without the new features**, and compare the results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_log = {'clf__C': [0.0001, 0.0005]}\n",
    "param_grid_tree = {'clf__max_depth': [5, 7, 10]}\n",
    "param_grid_rf = {'clf__n_estimators': [150], 'clf__max_depth': [7, 10], 'clf__n_jobs' : [-1]}\n",
    "param_grid_lgbm = {'clf__objective': ['binary'],\n",
    "                   'clf__metric': ['auc'],\n",
    "                   'clf__n_estimators': [150], \n",
    "                   'clf__max_depth': [7, 10]}\n",
    "\n",
    "predictions_base, search_res_base, feat_imp_base = classify(app_train.copy(),\n",
    "                                                 app_test.copy(),\n",
    "                                                 classifier = 'rf',\n",
    "                                                 cv = 3, \n",
    "                                                 param_grid = param_grid_rf,\n",
    "                                                 n_jobs = 1)\n",
    "\n",
    "for par, score in zip(search_res_base['params'], search_res_base['mean_test_score']) :\n",
    "    print(f\"Config: {par} -- score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_base.to_csv('base.csv', index = False)\n",
    "predictions.to_csv('add_feats.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "464705a1-7ecf-47ba-a1fe-9f870102eb85",
    "_uuid": "70322dd11709dcaaf879a56103fde8fc787b7d4c"
   },
   "source": [
    "## Polynomial Features\n",
    "\n",
    "One simple feature construction method is called [polynomial features](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html). In this method, we make features that are **powers** of existing features as well as **interaction terms** between existing features. For example, we can:\n",
    "\n",
    "- create variables `EXT_SOURCE_1^2` and `EXT_SOURCE_2^2` ...\n",
    "- ... also variables such as `EXT_SOURCE_1` x `EXT_SOURCE_2`, `EXT_SOURCE_1` x `EXT_SOURCE_2^2`, `EXT_SOURCE_1^2` x   `EXT_SOURCE_2^2`, and so on. \n",
    "\n",
    "These features that are a combination of multiple individual variables are called [interaction terms](https://en.wikipedia.org/wiki/Interaction_(statistics) because they capture the interactions between variables. In other words, while two variables by themselves may not have a strong influence on the target, combining them together into a single interaction variable might show a relationship with the target. [Interaction terms are commonly used in statistical models](https://www.theanalysisfactor.com/interpreting-interactions-in-regression/) to capture the effects of multiple variables, but I do not see them used as often in machine learning. Nonetheless, we can try out a few to see if they might help our model to predict whether or not a client will repay a loan. \n",
    "\n",
    "Jake VanderPlas writes about [polynomial features in his excellent book Python for Data Science](https://jakevdp.github.io/PythonDataScienceHandbook/05.04-feature-engineering.html) for those who want more information.\n",
    "\n",
    "In the following code, we create polynomial features using the `EXT_SOURCE` variables and the `DAYS_BIRTH` variable. [Scikit-Learn has a useful class called `PolynomialFeatures`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) that creates the polynomials and the interaction terms up to a specified degree. We can use a degree of 3 to see the results (when we are creating polynomial features, we want to avoid using too high of a degree, both because the number of features scales exponentially with the degree, and because we can run into [problems with overfitting](http://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html#sphx-glr-auto-examples-model-selection-plot-underfitting-overfitting-py)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "app_train = pd.read_csv('./input/application_train.csv')\n",
    "app_test = pd.read_csv('./input/application_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e5b0efd9-67ac-4aa0-91e9-2141a87a6a8a",
    "_uuid": "a63d53dcac14c4ac2e31ea9c5e16b5d161c2415b"
   },
   "outputs": [],
   "source": [
    "# Make a new dataframe for polynomial features\n",
    "poly_features = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'TARGET']]\n",
    "poly_features_test = app_test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]\n",
    "\n",
    "# imputer for handling missing values\n",
    "imputer = SimpleImputer(strategy = 'median')\n",
    "\n",
    "poly_target = poly_features['TARGET']\n",
    "poly_features = poly_features.drop(columns = ['TARGET'])\n",
    "\n",
    "# Need to impute missing values\n",
    "poly_features = imputer.fit_transform(poly_features)\n",
    "poly_features_test = imputer.transform(poly_features_test)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "                                  \n",
    "# Create the polynomial object with specified degree\n",
    "poly_transformer = PolynomialFeatures(degree = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2be7c1ab-d1e5-40f2-b8e7-e2b2ce1e2f9a",
    "_uuid": "72c5ecaae9c6ff038d16cbd9208f1abb69912631"
   },
   "outputs": [],
   "source": [
    "# Train the polynomial features\n",
    "poly_transformer.fit(poly_features)\n",
    "\n",
    "# Transform the features\n",
    "poly_features = poly_transformer.transform(poly_features)\n",
    "poly_features_test = poly_transformer.transform(poly_features_test)\n",
    "print('Polynomial Features shape: ', poly_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a7833b1e-714c-4988-8cbf-757d01290d8f",
    "_uuid": "4d837e47bada5411ffce06266605f043c6ffe19e"
   },
   "source": [
    "This creates a **considerable number of new features**. To get the names we have to use the polynomial features `get_feature_names` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7465d1e6-d360-4029-afa7-67cb34f60249",
    "_uuid": "121f98d2ec9c81c5dabb911dc68562d0b2b6d737"
   },
   "outputs": [],
   "source": [
    "poly_transformer.get_feature_names(input_features = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7eaeb645-bb25-4ac5-884f-d1231ab6d88f",
    "_uuid": "4e68b80b2738ef46863b53b7b781f299d602d316"
   },
   "source": [
    "There are 35 features with individual features raised to powers up to degree 3 and interaction terms. Now, let's see whether any of these new features **are correlated with the target**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "95725a63-f8f2-4680-8f7a-4252f04e7f7f",
    "_uuid": "e712923de757457bb87a35ecaccd27007b351e6c"
   },
   "outputs": [],
   "source": [
    "# Put train features into dataframe\n",
    "poly_features = pd.DataFrame(poly_features, \n",
    "                             columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', \n",
    "                                                                           'EXT_SOURCE_3', 'DAYS_BIRTH']))\n",
    "print(poly_features.shape)\n",
    "print(poly_features.columns.values)\n",
    "\n",
    "# Add in the target\n",
    "poly_features['TARGET'] = poly_target\n",
    "\n",
    "# Find the correlations with the target\n",
    "poly_corrs = poly_features.corr()['TARGET'].sort_values()\n",
    "\n",
    "# Display most negative and most positive\n",
    "print(poly_corrs.head(10))\n",
    "print(poly_corrs.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "971de432-c65e-4c9a-a3c0-c923ed27ddcb",
    "_uuid": "082ac97a068afed6758ed191acf5ab485e39230c"
   },
   "source": [
    "Several of the new variables have a greater (in terms of absolute magnitude) correlation with the target than the original features. When we build machine learning models, we can try with and without these features to determine if they actually help the model learn. \n",
    "\n",
    "We will add these features to a copy of the training and testing data and then evaluate models with and without the features. Many times in machine learning, the only way to know if an approach will work is to try it out! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ed758ed436a86f92a8ee574999aa91089242ca7a"
   },
   "outputs": [],
   "source": [
    "# Put test features into dataframe\n",
    "poly_features_test = pd.DataFrame(poly_features_test, \n",
    "                                  columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', \n",
    "                                                                                'EXT_SOURCE_3', 'DAYS_BIRTH']))\n",
    "\n",
    "# Merge polynomial features into training dataframe\n",
    "poly_features['SK_ID_CURR'] = app_train['SK_ID_CURR']\n",
    "app_train_poly = app_train.merge(poly_features, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Merge polnomial features into testing dataframe\n",
    "poly_features_test['SK_ID_CURR'] = app_test['SK_ID_CURR']\n",
    "app_test_poly = app_test.merge(poly_features_test, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Align the dataframes\n",
    "app_train_poly, app_test_poly = app_train_poly.align(app_test_poly, join = 'inner', axis = 1)\n",
    "\n",
    "app_train_poly['TARGET'] = poly_target\n",
    "\n",
    "# Print out the new shapes\n",
    "print('Training data with polynomial features shape: ', app_train_poly.shape)\n",
    "print('Testing data with polynomial features shape:  ', app_test_poly.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e27d400f3ec5447cfe5e908952351f271d521784"
   },
   "source": [
    "It's hard to say ahead of time if these new features will be useful. The only way to tell for sure is to try them out! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "43d979aed7cdfd6d7bd6a995b5756a384bd2b7dc"
   },
   "source": [
    "### Make Predictions using Engineered Features\n",
    "\n",
    "The only way to see if the Polynomial Features and Domain knowledge improved the model is to train a test a model on these features! We can then compare the submission performance to that for the model without these features to gauge the effect of our feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_log = {'clf__C': [0.0001, 0.0005]}\n",
    "param_grid_tree = {'clf__max_depth': [5, 7, 10]}\n",
    "param_grid_rf = {'clf__n_estimators': [150], 'clf__max_depth': [7, 10], 'clf__n_jobs' : [-1]}\n",
    "param_grid_lgbm = {'clf__objective': ['binary'],\n",
    "                   'clf__metric': ['auc'],\n",
    "                   'clf__n_estimators': [150], \n",
    "                   'clf__max_depth': [7, 10]}\n",
    "\n",
    "predictions_poly, search_res_poly, feat_imp_poly = classify(app_train_poly.copy(),\n",
    "                                            app_test_poly.copy(),\n",
    "                                            classifier = 'rf',\n",
    "                                            cv = 3, \n",
    "                                            param_grid = param_grid_rf,\n",
    "                                            n_jobs = 1)\n",
    "\n",
    "for par, score in zip(search_res_poly['params'], search_res_poly['mean_test_score']) :\n",
    "    print(f\"Config: {par} -- score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_poly.to_csv('poly.csv', index = False)\n",
    "predictions_poly.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the model and the hyperparameters used, polynomial features may **improve classification accuracy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b742ed91-9dd6-4a7b-af5e-1d6e7128beb2",
    "_uuid": "b1805834b4d4eae38db4f68502aade956fc1e10f"
   },
   "source": [
    "## Model Interpretation: Feature Importances\n",
    "\n",
    "As a simple method to see which variables are the most relevant, we can look at the feature importances of the random forest. Given the correlations we saw in the exploratory data analysis, we should expect that the most important features are the `EXT_SOURCE` and the `DAYS_BIRTH`. We may use these feature importances as a method of dimensionality reduction in future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_poly.sort_values(ascending = False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a90e9368-5f7d-4179-a5cc-1025f32c6a81",
    "_uuid": "b912337a5f35f495398d8ae8b8576ceb7062fe50"
   },
   "outputs": [],
   "source": [
    "def plot_feature_importances(df):\n",
    "    \"\"\"\n",
    "    Plot importances returned by a model. This can work with any measure of\n",
    "    feature importance provided that higher importance is better. \n",
    "    \n",
    "    Args:\n",
    "        df (dataframe): feature importances. Must have the features in a column\n",
    "        called `features` and the importances in a column called `importance\n",
    "        \n",
    "    Returns:\n",
    "        shows a plot of the 15 most importance features\n",
    "        \n",
    "        df (dataframe): feature importances sorted by importance (highest to lowest) \n",
    "        with a column for normalized importance\n",
    "        \"\"\"\n",
    "    \n",
    "    # Sort features according to importance\n",
    "    df = df.sort_values(ascending = False)\n",
    "    \n",
    "    # Normalize the feature importances to add up to one\n",
    "    df_norm = df / df.sum()\n",
    "\n",
    "    # Make a horizontal bar chart of feature importances\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    # Need to reverse the index to plot most important on top\n",
    "    ax.barh(list(df_norm.index[:15]), \n",
    "            df_norm.head(15), \n",
    "            align = 'center', edgecolor = 'k')\n",
    "    \n",
    "    # Set the yticks and labels\n",
    "    ax.set_yticks(list(df_norm.index[:15]))\n",
    "    \n",
    "    # Plot labeling\n",
    "    plt.xlabel('Normalized Importance'); plt.title('Feature Importances')\n",
    "    plt.show()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1084ad42-bc44-438b-b2fd-5fd7a1c1b363",
    "_uuid": "37309c4a94b248ad85fa7a0825f01830a818ba92"
   },
   "outputs": [],
   "source": [
    "# Show the feature importances for the default features\n",
    "feature_importances_sorted = plot_feature_importances(feat_imp_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "524c6aa12acc80e7018750e7a8897dc6b4bacf18"
   },
   "source": [
    "As expected, the most important features are those dealing with `EXT_SOURCE` and `DAYS_BIRTH`. We see that there are only a handful of features with a significant importance to the model, which suggests we may be able to drop many of the features without a decrease in performance (and we may even see an increase in performance.) Feature importances are not the most sophisticated method to interpret a model or perform dimensionality reduction, but they let us start to understand what factors our model takes into account when it makes predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "516e4b2eedeec2ff441f1ff034fbe4a73374bba2"
   },
   "outputs": [],
   "source": [
    "feature_importances_domain_sorted = plot_feature_importances(feat_imp_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4a2cdf24d5ecc01539d10902a9c7af6a13096086"
   },
   "source": [
    "We see that all four of our hand-engineered features made it into the top 15 most important! This should give us confidence that our domain knowledge was at least partially on track."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
