{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9d7057b0f4ce0d2bb50bfea37c29ce0927cdf53f"
   },
   "source": [
    "# Some feature engineering (part II)\n",
    "\n",
    "In this notebook, we will explore making features by hand for the Home Credit Default Risk competition. In an earlier notebook, we used only the `application` data in order to build a model. The best model we made from this data achieved a score on the leaderboard around 0.74. In order to better this score, we will have to include more information from the other dataframes. Here, we will look at using information from the `bureau` and `bureau_balance` data. The definitions of these data files are:\n",
    "\n",
    "* bureau: information about client's previous loans with other financial institutions reported to Home Credit. Each previous loan has its own row.\n",
    "* bureau_balance: monthly information about the previous loans. Each month has its own row.\n",
    "\n",
    "Manual feature engineering can be a tedious process (which is why we use automated feature engineering with featuretools!) and often relies on domain expertise. Since I have limited domain knowledge of loans and what makes a person likely to default, I will **instead focus on getting as much info as possible into the final training dataframe**. \n",
    "\n",
    "The idea is that the model will then **pick up on which features are important**, rather than us having to decide that. Basically, our approach is to make as many features as possible and then give them all to the model to use! Later, we can perform feature reduction using the feature importances from the model or other techniques such as PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b4e0980ff7f4d8d9f0661b5d5ebf07e66d304222"
   },
   "source": [
    "## Example: Counts of a client's previous loans\n",
    "\n",
    "To illustrate the general process of manual feature engineering, we will first simply get the count of a client's previous loans at other financial institutions. This requires a number of Pandas operations we will make heavy use of throughout the notebook:\n",
    "\n",
    "* `groupby`: group a dataframe by a column. In this case we will group by the unique client, the `SK_ID_CURR` column\n",
    "* `agg`: perform a calculation on the grouped data such as taking the mean of columns. We can either call the function directly (`grouped_df.mean()`) or use the `agg` function together with a list of transforms (e.g., `grouped_df.agg([mean, max, min, sum])`)\n",
    "* `merge`: match the aggregated statistics to the appropriate client. We need to merge the original training data with the calculated stats on the `SK_ID_CURR` column which will insert `NaN` in any cell for which the client does not have the corresponding statistic\n",
    "\n",
    "We also use the (`rename`) function quite a bit specifying the columns to be renamed as a dictionary. This is useful in order to keep track of the new variables we create.\n",
    "\n",
    "This might seem like a lot, which is why we'll eventually write a function to do this process for us. Let's take a look at implementing this by hand first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Read in bureau\n",
    "bureau = pd.read_csv('./input/bureau.csv')\n",
    "bureau.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6665d87bd3a157c20fb5a383322aa153005cad2b"
   },
   "outputs": [],
   "source": [
    "# Groupby the client id (SK_ID_CURR), count the number of previous loans, and rename the column\n",
    "previous_loan_counts = bureau.groupby('SK_ID_CURR', as_index=False)['SK_ID_BUREAU'].count().rename(columns = {'SK_ID_BUREAU': 'previous_loan_counts'})\n",
    "previous_loan_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1adcc4acb891adae8646211db629fb263660c2bb"
   },
   "outputs": [],
   "source": [
    "# Join to the training dataframe\n",
    "train = pd.read_csv('./input/application_train.csv')\n",
    "train = train.merge(previous_loan_counts, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Fill the missing values with 0 \n",
    "train['previous_loan_counts'] = train['previous_loan_counts'].fillna(0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "53d83da3d8a28541c2dd49be8047e110034c10e6"
   },
   "source": [
    "Scroll all the way to the right to see the new column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "173b8548125c8a344f67d397d7c24af223af7254"
   },
   "source": [
    "## Assessing Usefulness of New Variable with r value\n",
    "\n",
    "To determine if the new variable is useful, we can calculate the Pearson Correlation Coefficient (r-value) between this variable and the target. This measures the strength of a linear relationship between two variables and ranges from -1 (perfectly negatively linear) to +1 (perfectly positively linear). The r-value is not best measure of the \"usefulness\" of a new variable, but it can give a first approximation of whether a variable will be helpful to a machine learning model. The **larger** the r-value of a variable with respect to the target, **the more a change in this variable is likely to affect the value of the target**. Therefore, we look for the variables with the greatest absolute value r-value relative to the target.\n",
    "\n",
    "We can also visually inspect the relationship between some feature and the target using the Kernel Density Estimate (KDE) plot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f5bc72f178a44d45399f620ee43483df2482c02f"
   },
   "source": [
    "### Kernel Density Estimate Plots\n",
    "\n",
    "The kernel density estimate plot shows the distribution of a single variable (think of it as a smoothed histogram). To see the different in distributions dependent on the value of a categorical variable, we can color the distributions differently according to the category. For example, we can show the kernel density estimate of the `previous_loan_count` colored by whether the `TARGET` = 1 or 0. The resulting KDE will show any significant differences in the distribution of the variable between people who did not repay their loan (`TARGET == 1`) and the people who did (`TARGET == 0`). This can serve as an indicator of whether a variable will be 'relevant' to a machine learning model. \n",
    "\n",
    "We will put this plotting functionality in a function to re-use for any variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a5fab58ab8327c7f53361b584603d78df96c7a4"
   },
   "outputs": [],
   "source": [
    "# Plots the disribution of a variable colored by value of the target\n",
    "def kde_target(var_name, df):\n",
    "    \n",
    "    # Calculate the correlation coefficient between the new variable and the target\n",
    "    corr = df['TARGET'].corr(df[var_name])\n",
    "    \n",
    "    # Calculate medians for repaid vs not repaid\n",
    "    avg_repaid = df.loc[df['TARGET'] == 0, var_name].median()\n",
    "    avg_not_repaid = df.loc[df['TARGET'] == 1, var_name].median()\n",
    "    \n",
    "    plt.figure(figsize = (12, 6))\n",
    "    \n",
    "    # Plot the distribution for target == 0 and target == 1\n",
    "    sns.kdeplot(df.loc[df['TARGET'] == 0, var_name], label = 'TARGET == 0')\n",
    "    sns.kdeplot(df.loc[df['TARGET'] == 1, var_name], label = 'TARGET == 1')\n",
    "    \n",
    "    # label the plot\n",
    "    plt.xlabel(var_name); plt.ylabel('Density'); plt.title('%s Distribution' % var_name)\n",
    "    plt.legend();\n",
    "    \n",
    "    # print out the correlation\n",
    "    print('The correlation between %s and the TARGET is %0.4f' % (var_name, corr))\n",
    "    # Print out average values\n",
    "    print('Median value for loan that was not repaid = %0.4f' % avg_not_repaid)\n",
    "    print('Median value for loan that was repaid =     %0.4f' % avg_repaid)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "783e2b23b473f5f61d17ba5b5b64349d3a1d60cf"
   },
   "source": [
    "We can test this function using the `EXT_SOURCE_3` variable which we [found to be one of the most important variables ](https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction) according to a Random Forest and Gradient Boosting Machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f9e51eb7f02c5612edef3c950ae89da3b8ececf4"
   },
   "outputs": [],
   "source": [
    "kde_target('EXT_SOURCE_3', train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c4598cb54ad22b04646683832e2e4c4bc98ff8e9"
   },
   "source": [
    "Now for the new variable we just made, the number of previous loans at other institutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bbae3d4e85f106c1e7b457ad71e1549c0e7b1267"
   },
   "outputs": [],
   "source": [
    "kde_target('previous_loan_counts', train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a85c4e3f8ccb54bb4dbbd85a414744d301916fd8"
   },
   "source": [
    "From this it's difficult to tell if this variable will be important. The correlation coefficient is extremely weak and there is almost no noticeable difference in the distributions. \n",
    "\n",
    "Let's move on to make a few more variables from the bureau dataframe. We will take the mean, min, and max of every numeric column in the bureau dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "11f1b0ab2146ec95a50055d2788b5f05c43e0afb"
   },
   "source": [
    "## Aggregating Numeric Columns\n",
    "\n",
    "To account for the numeric information in the `bureau` dataframe, we can compute statistics for all the numeric columns. To do so, we `groupby` the client id, `agg` the grouped dataframe, and merge the result back into the training data. The `agg` function will only calculate the values for the numeric columns where the operation is considered valid. We will stick to using `'mean', 'max', 'min', 'sum'` but any function can be passed in here. We can even write our own function and use it in an `agg` call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "582885d850fa1316ce869b856b9d886ad542b04b"
   },
   "outputs": [],
   "source": [
    "# Group by the client id, calculate aggregation statistics\n",
    "bureau_agg = bureau.drop(columns = ['SK_ID_BUREAU']).groupby('SK_ID_CURR', as_index = False).agg(['count', 'mean', 'max', 'min', 'sum']).reset_index()\n",
    "display(bureau_agg)\n",
    "bureau_agg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "812f7b1e0d6016768d9276da790b0986181f9fdd"
   },
   "source": [
    "We need to create new names for each of these columns. The following code makes new names by appending the stat to the name. Here we have to deal with the fact that the dataframe has a multi-level index. I find these confusing and hard to work with, so I try to reduce to a single level index as quickly as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "01acafad68d285c875018ae916c002e9dad1a2fa"
   },
   "outputs": [],
   "source": [
    "# List of column names\n",
    "columns = ['SK_ID_CURR']\n",
    "\n",
    "# Iterate through the variables names\n",
    "for var in bureau_agg.columns.levels[0]:\n",
    "    # Skip the id name\n",
    "    if var != 'SK_ID_CURR':\n",
    "        \n",
    "        # Iterate through the stat names\n",
    "        for stat in bureau_agg.columns.levels[1][:-1]:\n",
    "            # Make a new column name for the variable and stat\n",
    "            columns.append('bureau_%s_%s' % (var, stat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4f34abd311ffcb34e9feb0786998e478ffd90766"
   },
   "outputs": [],
   "source": [
    "# Assign the list of columns names as the dataframe column names\n",
    "bureau_agg.columns = columns\n",
    "bureau_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "13c6a8b69a3bdbd1bf2d420d984f78400fc969d3"
   },
   "source": [
    "Now we simply merge with the training data as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2da1e6aa5651f4567813896d79d2e087fd5e7749"
   },
   "outputs": [],
   "source": [
    "# Merge with the training data\n",
    "train = train.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "290cf9aaa44d462f0f987ef35bb22b0010bd01a0"
   },
   "source": [
    "### Correlations of Aggregated Values with Target\n",
    "\n",
    "We can calculate the correlation of all new values with the target. Again, we can use these as an approximation of the variables which may be important for modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8cf94533bb8df06623f70d0cb01c24156f8af689"
   },
   "outputs": [],
   "source": [
    "# List of new correlations\n",
    "new_corrs = []\n",
    "\n",
    "# Iterate through the columns \n",
    "for col in columns:\n",
    "    # Calculate correlation with the target\n",
    "    corr = train['TARGET'].corr(train[col])\n",
    "    \n",
    "    # Append the list as a tuple\n",
    "\n",
    "    new_corrs.append((col, corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "774fe7e4c3e2708de823d3f94f65137b56bc2c2a"
   },
   "source": [
    "In the code below, we sort the correlations by the magnitude (absolute value) using the `sorted` Python function. We also make use of an anonymous `lambda` function, another important Python operation that is good to know. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2802a2568214396e919837353683c63867d38a17"
   },
   "outputs": [],
   "source": [
    "# Sort the correlations by the absolute value\n",
    "# Make sure to reverse to put the largest values at the front of list\n",
    "new_corrs = sorted(new_corrs, key = lambda x: abs(x[1]), reverse = True)\n",
    "new_corrs[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "581f41a665ed3b23d8b28a6e3050a11bc8a68dcf"
   },
   "source": [
    "None of the new variables have a significant correlation with the TARGET. We can look at the KDE plot of the highest correlated variable, `bureau_DAYS_CREDIT_mean`, with the target in  in terms of absolute magnitude correlation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "be155ee8fd05290d11a205b95f4b553b8ade06e3"
   },
   "outputs": [],
   "source": [
    "kde_target('bureau_DAYS_CREDIT_mean', train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58ca4b2852b486fa10e1bf31c2a7e61e9de52dd7"
   },
   "source": [
    "The definition of this column is: \"How many days before current application did client apply for Credit Bureau credit\". My interpretation is this is the number of days that the previous loan was applied for before the application for a loan at Home Credit. Therefore, a larger negative number indicates the loan was further before the current loan application. We see an extremely weak positive relationship between the average of this variable and the target meaning that clients who applied for loans further in the past potentially are more likely to repay loans at Home Credit. With a correlation this weak though, it is just as likely to be noise as a signal. \n",
    "\n",
    "#### The Multiple Comparisons Problem\n",
    "\n",
    "When we have lots of variables, we expect some of them to be correlated just by pure chance, a [problem known as multiple comparisons](https://towardsdatascience.com/the-multiple-comparisons-problem-e5573e8b9578). We can make hundreds of features, and some will turn out to be correlated with the target simply because of random noise in the data. Then, when our model trains, it may overfit to these variables because it thinks they have a relationship with the target in the training set, but this does not necessarily generalize to the test set. There are many considerations that we have to take into account when making features! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "645ab51cb64cd20f122d61e17ef8ad1ed78443cc"
   },
   "source": [
    "## Function for Numeric Aggregations\n",
    "\n",
    "Let's encapsulate all of the previous work into a function. This will allow us to compute aggregate stats for numeric columns across any dataframe. We will re-use this function when we want to apply the same operations for other dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8203852b47164d7800f69e572dda2cbe83c50976"
   },
   "outputs": [],
   "source": [
    "def agg_numeric(df, group_var, df_name):\n",
    "    \"\"\"Aggregates the numeric values in a dataframe. This can\n",
    "    be used to create features for each instance of the grouping variable.\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        df (dataframe): \n",
    "            the dataframe to calculate the statistics on\n",
    "        group_var (string): \n",
    "            the variable by which to group df\n",
    "        df_name (string): \n",
    "            the variable used to rename the columns\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        agg (dataframe): \n",
    "            a dataframe with the statistics aggregated for \n",
    "            all numeric columns. Each instance of the grouping variable will have \n",
    "            the statistics (mean, min, max, sum; currently supported) calculated. \n",
    "            The columns are also renamed to keep track of features created.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Remove id variables other than grouping variable\n",
    "    for col in df:\n",
    "        if col != group_var and 'SK_ID' in col:\n",
    "            df = df.drop(columns = col)\n",
    "            \n",
    "    group_ids = df[group_var]\n",
    "    numeric_df = df.select_dtypes('number')\n",
    "    numeric_df[group_var] = group_ids\n",
    "\n",
    "    # Group by the specified variable and calculate the statistics\n",
    "    agg = numeric_df.groupby(group_var).agg(['count', 'mean', 'max', 'min', 'sum']).reset_index()\n",
    "\n",
    "    # Need to create new column names\n",
    "    columns = [group_var]\n",
    "\n",
    "    # Iterate through the variables names\n",
    "    for var in agg.columns.levels[0]:\n",
    "        # Skip the grouping variable\n",
    "        if var != group_var:\n",
    "            # Iterate through the stat names\n",
    "            for stat in agg.columns.levels[1][:-1]:\n",
    "                # Make a new column name for the variable and stat\n",
    "                columns.append('%s_%s_%s' % (df_name, var, stat))\n",
    "\n",
    "    agg.columns = columns\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2784423d6e900b66f108cb2e6a425d63eb28743e"
   },
   "outputs": [],
   "source": [
    "bureau_agg_new = agg_numeric(bureau.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'bureau')\n",
    "bureau_agg_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "171660155dd332d9df85f61fdd7004a9f2593e59"
   },
   "source": [
    "To make sure the function worked as intended, we should compare with the aggregated dataframe we constructed by hand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "57dab1b1b23d0bd0167c9367688b56b43066a721"
   },
   "outputs": [],
   "source": [
    "bureau_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "af5a3d2ebc6850707c0bb021bc08df50b98d008b"
   },
   "source": [
    "If we go through and inspect the values, we do find that they are equivalent. We will be able to reuse this function for calculating numeric stats for other dataframes. Using functions allows for consistent results and decreases the amount of work we have to do in the future! \n",
    "\n",
    "### Correlation Function\n",
    "\n",
    "Before we move on, we can also make the code to calculate correlations with the target into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f55cdb9e28c9fcdb16b7922ce90c99ddda590e67"
   },
   "outputs": [],
   "source": [
    "# Function to calculate correlations with the target for a dataframe\n",
    "def target_corrs(df):\n",
    "\n",
    "    # List of correlations\n",
    "    corrs = []\n",
    "\n",
    "    # Iterate through the columns\n",
    "    # NOTE: we need to leave out columns which type is not numerical...\n",
    "    df_temp = df.select_dtypes(include='number')\n",
    "    for col in df_temp.columns:\n",
    "        print(col)\n",
    "        # Skip the target column\n",
    "        if col != 'TARGET':\n",
    "            # Calculate correlation with the target\n",
    "            corr = df_temp['TARGET'].corr(df_temp[col])\n",
    "\n",
    "            # Append the list as a tuple\n",
    "            corrs.append((col, corr))\n",
    "            \n",
    "    # Sort by absolute magnitude of correlations\n",
    "    corrs = sorted(corrs, key = lambda x: abs(x[1]), reverse = True)\n",
    "    \n",
    "    return corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Join to the training dataframe\n",
    "print(\"Join...\")\n",
    "train = train.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "print(\"Computing correlations...\")\n",
    "target_corrs(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a86ad170924ebf66122d24083679d2a061a080ff"
   },
   "source": [
    "## Categorical Variables\n",
    "\n",
    "Now we move from the numeric columns to the categorical columns. These are discrete string variables, so we cannot just calculate statistics such as mean \n",
    "and max which only work with numeric variables. Instead, we will rely on calculating value counts of each category within each categorical variable. As an example, if we have the following dataframe:\n",
    "\n",
    "| SK_ID_CURR | Loan type |\n",
    "|------------|-----------|\n",
    "| 1          | home      |\n",
    "| 1          | home      |\n",
    "| 1          | home      |\n",
    "| 1          | credit    |\n",
    "| 2          | credit    |\n",
    "| 3          | credit    |\n",
    "| 3          | cash      |\n",
    "| 3          | cash      |\n",
    "| 4          | credit    |\n",
    "| 4          | home      |\n",
    "| 4          | home      |\n",
    "\n",
    "we will use this information counting the number of loans in each category for each client. \n",
    "\n",
    "| SK_ID_CURR | credit count | cash count | home count | total count |\n",
    "|------------|--------------|------------|------------|-------------|\n",
    "| 1          | 1            | 0          | 3          | 4           |\n",
    "| 2          | 1            | 0          | 0          | 1           |\n",
    "| 3          | 1            | 2          | 0          | 3           |\n",
    "| 4          | 1            | 0          | 2          | 3           |\n",
    "\n",
    "\n",
    "Then we can normalize these value counts by the total number of occurences of that categorical variable for that observation (meaning that the normalized counts must sum to 1.0 for each observation).\n",
    "\n",
    "| SK_ID_CURR | credit count | cash count | home count | total count | credit count norm | cash count norm | home count norm |\n",
    "|------------|--------------|------------|------------|-------------|-------------------|-----------------|-----------------|\n",
    "| 1          | 1            | 0          | 3          | 4           | 0.25              | 0               | 0.75            |\n",
    "| 2          | 1            | 0          | 0          | 1           | 1.00              | 0               | 0               |\n",
    "| 3          | 1            | 2          | 0          | 3           | 0.33              | 0.66            | 0               |\n",
    "| 4          | 1            | 0          | 2          | 3           | 0.33              | 0               | 0.66            |\n",
    "\n",
    "Hopefully, encoding the categorical variables this way will allow us to capture the information they contain. If anyone has a better idea for this process, please let me know in the comments!\n",
    "We will now go through this process step-by-step. At the end, we will wrap up all the code into one function to be re-used for many dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3a8c1a8a74741d727a17ec0e83c237abb931e89e"
   },
   "source": [
    "First we one-hot encode a dataframe with only the categorical columns (`dtype == 'object'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd9fee51331a8181b29867d04b568336aa2bd445"
   },
   "outputs": [],
   "source": [
    "categorical = pd.get_dummies(bureau.select_dtypes('object'))\n",
    "categorical['SK_ID_CURR'] = bureau['SK_ID_CURR']\n",
    "categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "839ae477431e4131cfecc3bc0b2046ee964c6623"
   },
   "outputs": [],
   "source": [
    "categorical_grouped = categorical.groupby('SK_ID_CURR').agg(['sum', 'mean'])\n",
    "categorical_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ed965c98dee32b0b9194a97c0babd1ade9896e52"
   },
   "source": [
    "The `sum` columns represent the count of that category for the associated client and the `mean` represents the normalized count. One-hot encoding makes the process of calculating these figures very easy!\n",
    "\n",
    "We can use a similar function as before to rename the columns. Again, we have to deal with the multi-level index for the columns. We iterate through the first level (level 0) which is the name of the categorical variable appended with the value of the category (from one-hot encoding). Then we iterate  stats we calculated for each client. We will rename the column with the level 0 name appended with the stat. As an example, the column with `CREDIT_ACTIVE_Active` as level 0 and `sum` as level 1 will become `CREDIT_ACTIVE_Active_count`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0348b245ddb0e1f7bfa1e72b5c2e5b04416f66b"
   },
   "outputs": [],
   "source": [
    "categorical_grouped.columns.levels[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dbfa21f67f3fa910bdb052f482c6cbf684a2e474"
   },
   "outputs": [],
   "source": [
    "categorical_grouped.columns.levels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "41dccd044bedbf169b761daeff0e5d7b177d08ef"
   },
   "outputs": [],
   "source": [
    "group_var = 'SK_ID_CURR'\n",
    "\n",
    "# Need to create new column names\n",
    "columns = []\n",
    "\n",
    "# Iterate through the variables names\n",
    "for var in categorical_grouped.columns.levels[0]:\n",
    "    # Skip the grouping variable\n",
    "    if var != group_var:\n",
    "        # Iterate through the stat names\n",
    "        for stat in ['count', 'count_norm']:\n",
    "            # Make a new column name for the variable and stat\n",
    "            columns.append('%s_%s' % (var, stat))\n",
    "\n",
    "#  Rename the columns\n",
    "categorical_grouped.columns = columns\n",
    "\n",
    "categorical_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6ebc592c38c6d7664c7c57d3884ea80dfeabf760"
   },
   "source": [
    "The sum column records the counts and the mean column records the normalized count. \n",
    "\n",
    "We can merge this dataframe into the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "69e0695167a8e793c1a1d3934f8a8e510343606d"
   },
   "outputs": [],
   "source": [
    "train = train.merge(categorical_grouped, left_on = 'SK_ID_CURR', right_index = True, how = 'left')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "072b94cbbc2dba8df21d777e46bc693d731fd512"
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "28ba0118d6544d6d4fe436901ee9dc8834ae1b0e"
   },
   "outputs": [],
   "source": [
    "train.iloc[:10, 123:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a30770ca960821a6c915f6acd54161a37bffb432"
   },
   "source": [
    "### Function to Handle Categorical Variables\n",
    "\n",
    "To make the code more efficient, we can now write a function to handle the categorical variables for us. This will take the same form as the `agg_numeric` function in that it accepts a dataframe and a grouping variable. Then it will calculate the counts and normalized counts of each category for all categorical variables in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ddc7decf9497eaa536255d601f76c3a6259fca6b"
   },
   "outputs": [],
   "source": [
    "def count_categorical(df, group_var, df_name):\n",
    "    \"\"\"Computes counts and normalized counts for each observation\n",
    "    of `group_var` of each unique category in every categorical variable\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    df : dataframe \n",
    "        The dataframe to calculate the value counts for.\n",
    "        \n",
    "    group_var : string\n",
    "        The variable by which to group the dataframe. For each unique\n",
    "        value of this variable, the final dataframe will have one row\n",
    "        \n",
    "    df_name : string\n",
    "        Variable added to the front of column names to keep track of columns\n",
    "\n",
    "    \n",
    "    Return\n",
    "    --------\n",
    "    categorical : dataframe\n",
    "        A dataframe with counts and normalized counts of each unique category in every categorical variable\n",
    "        with one row for every unique value of the `group_var`.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Select the categorical columns\n",
    "    categorical = pd.get_dummies(df.select_dtypes('object'))\n",
    "\n",
    "    # Make sure to put the identifying id on the column\n",
    "    categorical[group_var] = df[group_var]\n",
    "\n",
    "    # Groupby the group var and calculate the sum and mean\n",
    "    categorical = categorical.groupby(group_var).agg(['sum', 'mean'])\n",
    "    \n",
    "    column_names = []\n",
    "    \n",
    "    # Iterate through the columns in level 0\n",
    "    for var in categorical.columns.levels[0]:\n",
    "        # Iterate through the stats in level 1\n",
    "        for stat in ['count', 'count_norm']:\n",
    "            # Make a new column name\n",
    "            column_names.append('%s_%s_%s' % (df_name, var, stat))\n",
    "    \n",
    "    categorical.columns = column_names\n",
    "    \n",
    "    return categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0f1629b07ec6e75e98da459f22611d275fcb282"
   },
   "outputs": [],
   "source": [
    "bureau_counts = count_categorical(bureau, group_var = 'SK_ID_CURR', df_name = 'bureau')\n",
    "bureau_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cecd442561b3a8405721875878bcbb90c94f2517"
   },
   "source": [
    "### Applying Operations to another dataframe\n",
    "\n",
    "We will now turn to the bureau balance dataframe. This dataframe has monthly information about each client's previous loan(s) with other financial institutions. Instead of grouping this dataframe by the `SK_ID_CURR` which is the client id, we will first group the dataframe by the `SK_ID_BUREAU` which is the id of the previous loan. This will give us one row of the dataframe for each loan. Then, we can group by the `SK_ID_CURR` and calculate the aggregations across the loans of each client. The final result will be a dataframe with one row for each client, with stats calculated for their loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b49d1c1553eb3c0a8887d967fe9c981b015a7e40"
   },
   "outputs": [],
   "source": [
    "# Read in bureau balance\n",
    "bureau_balance = pd.read_csv('./input/bureau_balance.csv')\n",
    "bureau_balance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "815ea915661653e3322e5cbf0f60614754411526"
   },
   "source": [
    "First, we can calculate the value counts of each status for each loan. Fortunately, we already have a function that does this for us! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "891d69c6cf3634d2fab71b0c8cc1eb212f433083"
   },
   "outputs": [],
   "source": [
    "# Counts of each type of status for each previous loan\n",
    "bureau_balance_counts = count_categorical(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\n",
    "display(bureau_balance_counts.head())\n",
    "bureau_balance_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4b1b1623a426efd45f7488636ffffc6b54c68d8e"
   },
   "source": [
    "Now we can handle the one numeric column. The `MONTHS_BALANCE` column has the \"months of balance relative to application date.\" This might not necessarily be that important as a numeric variable, and in future work we might want to consider this as a time variable. For now, we can just calculate the same aggregation statistics as previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da531864649dc2b8dab18c31019fc36d6ec6469d"
   },
   "outputs": [],
   "source": [
    "# Calculate value count statistics for each `SK_ID_CURR` \n",
    "bureau_balance_agg = agg_numeric(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\n",
    "display(bureau_balance_agg.head())\n",
    "bureau_balance_agg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "50b714b2165463138c29715ad68919bcc47aac2d"
   },
   "source": [
    "The above dataframes have the calculations done on each _loan_. Now we need to aggregate these for each _client_. We can do this by merging the dataframes together first and then since all the variables are numeric, we just need to aggregate the statistics again, this time grouping by the `SK_ID_CURR`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dbd657d3cbe3cf9948ba8d7543f6653e61025bc6"
   },
   "outputs": [],
   "source": [
    "# Dataframe grouped by the loan\n",
    "bureau_by_loan = bureau_balance_agg.merge(bureau_balance_counts, right_index = True, left_on = 'SK_ID_BUREAU', how = 'outer')\n",
    "\n",
    "# Merge to include the SK_ID_CURR\n",
    "bureau_by_loan = bureau_by_loan.merge(bureau[['SK_ID_BUREAU', 'SK_ID_CURR']], on = 'SK_ID_BUREAU', how = 'left')\n",
    "\n",
    "bureau_by_loan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae22ded2231b37858d9d1d0c3c5b0eb72202c6ab"
   },
   "outputs": [],
   "source": [
    "bureau_balance_by_client = agg_numeric(bureau_by_loan.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'client')\n",
    "bureau_balance_by_client.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fb037a66b921c2dbf837e8d6ddb5179be51e8446"
   },
   "source": [
    "To recap, for the `bureau_balance` dataframe we:\n",
    "\n",
    "1. Calculated numeric stats grouping by each loan\n",
    "2. Made value counts of each categorical variable grouping by loan\n",
    "3. Merged the stats and the value counts on the loans\n",
    "4. Calculated numeric stats for the resulting dataframe grouping by the client id\n",
    "\n",
    "The final resulting dataframe has one row for each client, with statistics calculated for all of their loans with monthly balance information. \n",
    "\n",
    "Some of these variables are a little confusing, so let's try to explain a few:\n",
    "\n",
    "* `client_bureau_balance_MONTHS_BALANCE_mean_mean`: For each loan calculate the mean value of `MONTHS_BALANCE`. Then for each client, calculate the mean of this value for all of their loans. \n",
    "* `client_bureau_balance_STATUS_X_count_norm_sum`: For each loan, calculate the number of occurences of `STATUS` == X divided by the number of total `STATUS` values for the loan. Then, for each client, add up the values for each loan. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e7c7be26bc22cacc8168f907d01c2c259ad6c867"
   },
   "source": [
    "We will hold off on calculating the correlations until we have all the variables together in one dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "90aa8e57fbff00777a1e62b060c2c06cf7845381"
   },
   "source": [
    "# Putting the Functions Together\n",
    "\n",
    "We now have all the pieces in place to take the information from the previous loans at other institutions and the monthly payments information about these loans and put them into the main training dataframe. Let's do a reset of all the variables and then use the functions we built to do this from the ground up. This demonstrate the benefit of using functions for repeatable workflows! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "26848bd0252a31559e254c454b905305701ee522"
   },
   "outputs": [],
   "source": [
    "# Free up memory by deleting old objects\n",
    "import gc\n",
    "gc.enable()\n",
    "del train, bureau, bureau_balance, bureau_agg, bureau_agg_new, bureau_balance_agg, bureau_balance_counts, bureau_by_loan, bureau_balance_by_client, bureau_counts\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc574b9486fb40f72146e6481b341931dd180e3d"
   },
   "outputs": [],
   "source": [
    "# Read in new copies of all the dataframes\n",
    "train = pd.read_csv('./input/application_train.csv')\n",
    "bureau = pd.read_csv('./input/bureau.csv')\n",
    "bureau_balance = pd.read_csv('./input/bureau_balance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "feba956fa449260cc71505cb9156887a62ca8337"
   },
   "source": [
    "### Counts of Bureau Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "491f45986682beb4ee2bd62c32c622830b3b0e76"
   },
   "outputs": [],
   "source": [
    "bureau_counts = count_categorical(bureau, group_var = 'SK_ID_CURR', df_name = 'bureau')\n",
    "bureau_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c4c80230ee098fa39f4446b7161f105cd18965bc"
   },
   "source": [
    "### Aggregated Stats of Bureau Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5f9d2491e244da4811f78f0340fd9d42127e9076"
   },
   "outputs": [],
   "source": [
    "bureau_agg = agg_numeric(bureau.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'bureau')\n",
    "bureau_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3ce2211679505e646121cc0b2f8b217ab9718ba6"
   },
   "source": [
    "### Value counts of Bureau Balance dataframe by loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e55cc0b41e66e77dfd19ac1b808edc4581a1206"
   },
   "outputs": [],
   "source": [
    "bureau_balance_counts = count_categorical(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\n",
    "bureau_balance_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7c2378a4fc130bc7de954c454d50e26adda6f9f6"
   },
   "source": [
    "### Aggregated stats of Bureau Balance dataframe by loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eb25294df7f998058e15e6ae24438c772d4ae86c"
   },
   "outputs": [],
   "source": [
    "bureau_balance_agg = agg_numeric(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\n",
    "bureau_balance_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f7343f605c4bc38c0c3af1b53bc258699e480dcf"
   },
   "source": [
    "### Aggregated Stats of Bureau Balance by Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9315370e38f25339af200a45809387f211464ce9"
   },
   "outputs": [],
   "source": [
    "# Dataframe grouped by the loan\n",
    "bureau_by_loan = bureau_balance_agg.merge(bureau_balance_counts, right_index = True, left_on = 'SK_ID_BUREAU', how = 'outer')\n",
    "\n",
    "# Merge to include the SK_ID_CURR\n",
    "bureau_by_loan = bureau[['SK_ID_BUREAU', 'SK_ID_CURR']].merge(bureau_by_loan, on = 'SK_ID_BUREAU', how = 'left')\n",
    "\n",
    "# Aggregate the stats for each client\n",
    "bureau_balance_by_client = agg_numeric(bureau_by_loan.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'client')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1f8f616b645ba974517be24adb30b4af4cf1afe3"
   },
   "source": [
    "## Insert Computed Features into Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f61f183707d7ca8d363a344b073dd9122acfdcc5"
   },
   "outputs": [],
   "source": [
    "original_features = list(train.columns)\n",
    "print('Original Number of Features: ', len(original_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "02f4310f7485d299c1588805ce24f3360afa6f42"
   },
   "outputs": [],
   "source": [
    "# Merge with the value counts of bureau\n",
    "train = train.merge(bureau_counts, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Merge with the stats of bureau\n",
    "train = train.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Merge with the monthly information grouped by client\n",
    "train = train.merge(bureau_balance_by_client, on = 'SK_ID_CURR', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f672226eee3059311d476c0eb68946988f9f5712"
   },
   "outputs": [],
   "source": [
    "new_features = list(train.columns)\n",
    "print('Number of features using previous loans from other institutions data: ', len(new_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e16d0c10cf2a0cc778db576a4ad233960c70a028"
   },
   "source": [
    "# Feature Engineering Outcomes\n",
    "\n",
    "After all that work, now we want to take a look at the variables we have created. We can look at the percentage of missing values, the correlations of variables with the target, and also the correlation of variables with the other variables. The correlations between variables can show if we have collinear varibles, that is, variables that are highly correlated with one another. Often, we want to remove one in a pair of collinear variables because having both variables would be redundant. We can also use the percentage of missing values to remove features with a substantial majority of values that are not present. __Feature selection__ will be an important focus going forward, because reducing the number of features can help the model learn during training and also generalize better to the testing data. The \"curse of dimensionality\" is the name given to the issues caused by having too many features (too high of a dimension). As the number of variables increases, the number of datapoints needed to learn the relationship between these variables and the target value increases exponentially. \n",
    "\n",
    "Feature selection is the process of removing variables to help our model to learn and generalize better to the testing set. The objective is to remove useless/redundant variables while preserving those that are useful. There are a number of tools we can use for this process, but in this notebook we will stick to removing columns with a high percentage of missing values and variables that have a high correlation with one another. Later we can look at using the feature importances returned from models such as the `Gradient Boosting Machine` or `Random Forest` to perform feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab576d2c245270ca843f825afab02583c091897d"
   },
   "source": [
    "## Missing Values\n",
    "\n",
    "An important consideration is the missing values in the dataframe. Columns with too many missing values might have to be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eef874f5edd28e7449e198264987b93566a5227a"
   },
   "outputs": [],
   "source": [
    "# Function to calculate missing values by column# Funct \n",
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dba1e683347bbd9b07a162675a4f79e08c28db0a"
   },
   "outputs": [],
   "source": [
    "missing_train = missing_values_table(train)\n",
    "missing_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f0defbc704277c67350cf2064b511800a3cdbad2"
   },
   "source": [
    "We see there are a number of columns with a high percentage of missing values. There is no well-established threshold for removing missing values, and the best course of action depends on the problem. Here, to reduce the number of features, we will remove any columns in either the training or the testing data that have greater than 90% missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5739842767f1a58e9c33a6683d5b0f32c97b69b3"
   },
   "outputs": [],
   "source": [
    "missing_train_vars = list(missing_train.index[missing_train['% of Total Values'] > 90])\n",
    "len(missing_train_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "055b96cb462b6876d6ae7f0e0c348426ddfc5cca"
   },
   "source": [
    "Before we remove the missing values, we will find the missing value percentages in the testing data. We'll then remove any columns with greater than 90% missing values in either the training or testing data.\n",
    "Let's now read in the testing data, perform the same operations, and look at the missing values in the testing data. We already have calculated all the counts and aggregation statistics, so we only need to merge the testing data with the appropriate data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dc3921576a8fb644b36f5119f169b88d30a51c01"
   },
   "source": [
    "## Calculate Information for Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "48be68ba3403d8e3f208b436219003b1f6097fad"
   },
   "outputs": [],
   "source": [
    "# Read in the test dataframe\n",
    "test = pd.read_csv('./input/application_test.csv')\n",
    "\n",
    "# Merge with the value counts of bureau\n",
    "test = test.merge(bureau_counts, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Merge with the stats of bureau\n",
    "test = test.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Merge with the value counts of bureau balance\n",
    "test = test.merge(bureau_balance_by_client, on = 'SK_ID_CURR', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ee6595328bd2eab6a89b542475500aaaa4b3947"
   },
   "outputs": [],
   "source": [
    "print('Shape of Testing Data: ', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "518da486b84f28f7ca9c1b366fdb2719f0e19f38"
   },
   "source": [
    "We need to align the testing and training dataframes, which means matching up the columns so they have the exact same columns. This shouldn't be an issue here, but when we one-hot encode variables, we need to align the dataframes to make sure they have the same columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "39d6e6a2b8af1bb15df0f98ff5eb601c2e828099"
   },
   "outputs": [],
   "source": [
    "train_labels = train['TARGET']\n",
    "\n",
    "# Align the dataframes, this will remove the 'TARGET' column\n",
    "train, test = train.align(test, join = 'inner', axis = 1)\n",
    "\n",
    "train['TARGET'] = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f3d3fcc7cf9a68208a6d6303565883cd58e7c531"
   },
   "outputs": [],
   "source": [
    "print('Training Data Shape: ', train.shape)\n",
    "print('Testing Data Shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "77cd0cbc96158d555ca156b93906497364cbdabd"
   },
   "source": [
    "The dataframes now have the same columns (with the exception of the `TARGET` column in the training data). This means we can use them in a machine learning model which needs to see the same columns in both the training and testing dataframes.\n",
    "\n",
    "Let's now look at the percentage of missing values in the testing data so we can figure out the columns that should be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ff8e3932b44097ae679ea7bb9b0464a077e07727"
   },
   "outputs": [],
   "source": [
    "missing_test = missing_values_table(test)\n",
    "missing_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1ecf51b6455fdef32ea7b50cdaf05eed211b15e7"
   },
   "outputs": [],
   "source": [
    "missing_test_vars = list(missing_test.index[missing_test['% of Total Values'] > 90])\n",
    "len(missing_test_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "caa333e30cf19898f4b902d64fbd790659c8f035"
   },
   "outputs": [],
   "source": [
    "missing_columns = list(set(missing_test_vars + missing_train_vars))\n",
    "print('There are %d columns with more than 90%% missing in either the training or testing data.' % len(missing_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ae7c69dc4112159c5e1356b06821ba169ac595d"
   },
   "outputs": [],
   "source": [
    "# Drop the missing columns\n",
    "train = train.drop(columns = missing_columns)\n",
    "test = test.drop(columns = missing_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ba618f25fe2fb25681228d518cc56f88572cf7fd"
   },
   "source": [
    "We ended up removing no columns in this round because there are no columns with more than 90% missing values. We might have to apply another feature selection method to reduce the dimensionality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "91197da37fcd84538520f03b50e0b060a19cc71d"
   },
   "source": [
    "At this point we will save both the training and testing data. I encourage anyone to try different percentages for dropping the missing columns and compare the outcomes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a7d15638e419b84bf164b20e5195db37885e3e0d"
   },
   "outputs": [],
   "source": [
    "train.to_csv('train_bureau_raw.csv', index = False)\n",
    "test.to_csv('test_bureau_raw.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9425c558df0c882cffe4fc07da41394a6fb3b422"
   },
   "source": [
    "## Correlations\n",
    "\n",
    "First let's look at the correlations of the variables with the target. We can see in any of the variables we created have a greater correlation than those already present in the training data (from `application`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "87c47e087eaacb846572ffdd58c22ca1f0ce0010"
   },
   "outputs": [],
   "source": [
    "# Calculate all correlations in dataframe\n",
    "corrs = train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "75c757ae81ff84d9e3453ca7c74ce59326e24b84"
   },
   "outputs": [],
   "source": [
    "corrs = corrs.sort_values('TARGET', ascending = False)\n",
    "\n",
    "# Ten most positive correlations\n",
    "pd.DataFrame(corrs['TARGET'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6774bdef9c97bc58191101414a0a067561f12160"
   },
   "outputs": [],
   "source": [
    "# Ten most negative correlations\n",
    "pd.DataFrame(corrs['TARGET'].dropna().tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0d98ec8d33f097aa3702933cfb64d82bfbd62232"
   },
   "source": [
    "The highest correlated variable with the target (other than the `TARGET` which of course has a correlation of 1), is a variable we created. However, just because the variable is correlated does not mean that it will be useful, and we have to remember that if we generate hundreds of new variables, some are going to be correlated with the target simply because of random noise. \n",
    "\n",
    "Viewing the correlations skeptically, it does appear that several of the newly created variables may be useful. To assess the \"usefulness\" of variables, we will look at the feature importances returned by the model. For curiousity's sake (and because we already wrote the function) we can make a kde plot of some newly created variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "17e1cb7c492b1c122556ac16472fbbdee5a1030a"
   },
   "outputs": [],
   "source": [
    "kde_target(var_name='bureau_CREDIT_ACTIVE_Active_count_norm', df=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dd71a301ca0fe799b5f36ddd07cf3224c03e1cd9"
   },
   "source": [
    "Well this distribution is all over the place. This variable represents the number of previous loans with a `CREDIT_ACTIVE` value of `Active` divided by the total number of previous loans for a client. The correlation here is so weak that I do not think we should draw any conclusions! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e6ed8ce92d28415771fe4e4cc872117a18357181"
   },
   "source": [
    "### Collinear Variables\n",
    "\n",
    "We can calculate not only the correlations of the variables with the target, but also the correlation of each variable with every other variable. This will allow us to see if there are highly collinear variables that should perhaps be removed from the data. \n",
    "\n",
    "Let's look for any variables that have a greather than 0.8 correlation with other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7330e7311864a70afa75b7e7c33ad4b3d77df040"
   },
   "outputs": [],
   "source": [
    "# Set the threshold\n",
    "threshold = 0.8\n",
    "\n",
    "# Empty dictionary to hold correlated variables\n",
    "above_threshold_vars = {}\n",
    "\n",
    "# For each column, record the variables that are above the threshold\n",
    "for col in corrs:\n",
    "    above_threshold_vars[col] = list(corrs.index[corrs[col] > threshold])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8dcfa3892d84efa2e0db448b9542c9effad01e85"
   },
   "source": [
    "For each of these pairs of highly correlated variables, we only want to remove one of the variables. The following code creates a set of variables to remove by only adding one of each pair. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0134543670e895436769c64a58bbdee7eb7a255f"
   },
   "outputs": [],
   "source": [
    "# Track columns to remove and columns already examined\n",
    "cols_to_remove = []\n",
    "cols_seen = []\n",
    "cols_to_remove_pair = []\n",
    "\n",
    "# Iterate through columns and correlated columns\n",
    "for key, value in above_threshold_vars.items():\n",
    "    # Keep track of columns already examined\n",
    "    cols_seen.append(key)\n",
    "    for x in value:\n",
    "        if x == key:\n",
    "            next\n",
    "        else:\n",
    "            # Only want to remove one in a pair\n",
    "            if x not in cols_seen:\n",
    "                cols_to_remove.append(x)\n",
    "                cols_to_remove_pair.append(key)\n",
    "            \n",
    "cols_to_remove = list(set(cols_to_remove))\n",
    "print('Number of columns to remove: ', len(cols_to_remove))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "be37ec11c061291e143c01102703103c0915ffcb"
   },
   "source": [
    "We can remove these columns from both the training and the testing datasets. We will have to compare performance after removing these variables with performance keeping these variables (the raw csv files we saved earlier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0fedcbce9bce99809bf7d4559b6ad93e8ecca8ea"
   },
   "outputs": [],
   "source": [
    "train_corrs_removed = train.drop(columns = cols_to_remove)\n",
    "test_corrs_removed = test.drop(columns = cols_to_remove)\n",
    "\n",
    "print('Training Corrs Removed Shape: ', train_corrs_removed.shape)\n",
    "print('Testing Corrs Removed Shape: ', test_corrs_removed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f4443a62f6e8987c0be2e3162589444ecd7d275"
   },
   "outputs": [],
   "source": [
    "train_corrs_removed.to_csv('train_bureau_corrs_removed.csv', index = False)\n",
    "test_corrs_removed.to_csv('test_bureau_corrs_removed.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "be48572e88f64f00b4221da7782ac834444c96b0"
   },
   "source": [
    "# Modeling \n",
    "\n",
    "To actually test the performance of these new datasets, we will try using them for machine learning! Let's first pull in some functions we used in the previous class..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def label_encode(app_train, app_test) : \n",
    "    le = LabelEncoder()\n",
    "    le_count = 0\n",
    "\n",
    "    # Iterate through the columns\n",
    "    for col in app_train:\n",
    "        if app_train[col].dtype == 'object':\n",
    "            # If 2 or fewer unique categories\n",
    "            set_values = app_train[col].unique()\n",
    "            num_values = len(list(set_values))\n",
    "            if num_values <= 2:\n",
    "                print(f\"{col} will be label encoded! Found {num_values} values: {set_values}\")\n",
    "                # Train on the training data\n",
    "                le.fit(app_train[col])\n",
    "                # Transform both training and testing data\n",
    "                app_train[col] = le.transform(app_train[col])\n",
    "                app_test[col] = le.transform(app_test[col])\n",
    "\n",
    "                # Keep track of how many columns were label encoded\n",
    "                le_count += 1\n",
    "\n",
    "    print('%d columns were label encoded.' % le_count)\n",
    "    print('Training Features shape: ', app_train.shape)\n",
    "    print('Testing Features shape: ', app_test.shape)\n",
    "    \n",
    "    return app_train, app_test\n",
    "\n",
    "\n",
    "def one_hot_encode(app_train, app_test) :\n",
    "    \n",
    "    # Let's perform the one-hot encoding of categorical features with > 2 values...\n",
    "    app_train = pd.get_dummies(app_train)\n",
    "    app_test = pd.get_dummies(app_test)\n",
    "    print('Training Features shape: ', app_train.shape)\n",
    "    print('Testing Features shape: ', app_test.shape)\n",
    "    \n",
    "    return app_train, app_test\n",
    "\n",
    "\n",
    "def align_train_test(app_train, app_test) :\n",
    "    \n",
    "    # Save target variable in a separate Series...\n",
    "    train_labels = app_train['TARGET']\n",
    "\n",
    "    # Align the training and testing data on columns -- this keeps only the columns present in both dataframes.\n",
    "    app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n",
    "\n",
    "    # Add the target column back in.\n",
    "    app_train['TARGET'] = train_labels\n",
    "    \n",
    "    return train_labels, app_train, app_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "\n",
    "def classify(app_train, app_test, classifier = 'logistic', cv = 5, param_grid = {}, n_jobs = 1) :\n",
    "    \n",
    "    # Pick the classifier desired by the user...\n",
    "    log_reg = LogisticRegression\n",
    "    if classifier == 'decision' : log_reg = DecisionTreeClassifier\n",
    "    elif classifier == 'SVC' : log_reg = SVC\n",
    "    elif classifier == 'rf' : log_reg = RandomForestClassifier\n",
    "    elif classifier == 'lgbm' : log_reg = LGBMClassifier\n",
    "    else : pass\n",
    "    \n",
    "    \n",
    "    # Label encoding, one hot encoding, train-test alignment.\n",
    "    app_train, app_test = label_encode(app_train, app_test)\n",
    "    app_train, app_test = one_hot_encode(app_train, app_test)\n",
    "    train_labels, app_train, app_test = align_train_test(app_train, app_test)\n",
    "    \n",
    "    \n",
    "    train = app_train.drop(columns = ['TARGET'], errors = 'ignore')\n",
    "    test = app_test.copy()\n",
    "    \n",
    " \n",
    "    # Setup the pipeline. \n",
    "    from sklearn.pipeline import Pipeline\n",
    "    clf = Pipeline([('imp', SimpleImputer(strategy = 'median')),\n",
    "                    ('sca', MinMaxScaler(feature_range = (0, 1))),\n",
    "                    ('clf', log_reg(class_weight = 'balanced'))],\n",
    "                    verbose = True)\n",
    "    \n",
    "\n",
    "    # Setup the grid search. \n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    search = GridSearchCV(estimator = clf, \n",
    "                          param_grid = param_grid, \n",
    "                          cv = cv,\n",
    "                          scoring = 'roc_auc',\n",
    "                          n_jobs = n_jobs,\n",
    "                          verbose = 1)\n",
    "    \n",
    "    \n",
    "    # Training ...\n",
    "    search.fit(train, train_labels)\n",
    "\n",
    "    \n",
    "    #print('Miscellanea of results:', search.cv_results_)\n",
    "    #print('Score achieved by the best config. during stratified CV:', search.best_score_)\n",
    "    #print('Best estimator config:', search.best_estimator_)\n",
    "\n",
    "    \n",
    "    # Compute predictions...\n",
    "    log_reg_pred = search.predict_proba(test)[:, 1]\n",
    "    # print(log_reg_pred)\n",
    "\n",
    "    \n",
    "    # Final result dataframe.\n",
    "    submit = app_test[['SK_ID_CURR']]\n",
    "    submit['TARGET'] = log_reg_pred\n",
    "    #submit.head()\n",
    "\n",
    "    \n",
    "    # Compute feature importance (if applicable).\n",
    "    feat_imp = pd.Series(0, index=train.columns)\n",
    "    if(classifier in ['rf', 'lgbm']) :\n",
    "        feat_imp = pd.Series(search.best_estimator_.named_steps[\"clf\"].feature_importances_, index=train.columns)\n",
    "        \n",
    "    # Return the results.\n",
    "    return submit, search.cv_results_, feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(df):\n",
    "    \"\"\"\n",
    "    Plot importances returned by a model. This can work with any measure of\n",
    "    feature importance provided that higher importance is better. \n",
    "    \n",
    "    Args:\n",
    "        df (dataframe): feature importances. Must have the features in a column\n",
    "        called `features` and the importances in a column called `importance\n",
    "        \n",
    "    Returns:\n",
    "        shows a plot of the 15 most importance features\n",
    "        \n",
    "        df (dataframe): feature importances sorted by importance (highest to lowest) \n",
    "        with a column for normalized importance\n",
    "        \"\"\"\n",
    "    \n",
    "    # Sort features according to importance\n",
    "    df = df.sort_values(ascending = False)\n",
    "    \n",
    "    # Normalize the feature importances to add up to one\n",
    "    df_norm = df / df.sum()\n",
    "\n",
    "    # Make a horizontal bar chart of feature importances\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    # Need to reverse the index to plot most important on top\n",
    "    ax.barh(list(df_norm.index[:15]), \n",
    "            df_norm.head(15), \n",
    "            align = 'center', edgecolor = 'k')\n",
    "    \n",
    "    # Set the yticks and labels\n",
    "    ax.set_yticks(list(df_norm.index[:15]))\n",
    "    \n",
    "    # Plot labeling\n",
    "    plt.xlabel('Normalized Importance'); plt.title('Feature Importances')\n",
    "    plt.show()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test one**: no use of engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_control = pd.read_csv('./input/application_train.csv')\n",
    "test_control = pd.read_csv('./input/application_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_log = {'clf__C': [0.0001, 0.0005]}\n",
    "param_grid_tree = {'clf__max_depth': [5, 7, 10]}\n",
    "param_grid_rf = {'clf__n_estimators': [150], 'clf__max_depth': [7, 10], 'clf__n_jobs' : [-1]}\n",
    "param_grid_lgbm = {'clf__objective': ['binary'],\n",
    "                   'clf__metric': ['auc'],\n",
    "                   'clf__n_estimators': [150], \n",
    "                   'clf__max_depth': [7, 10]}\n",
    "\n",
    "predictions_base, search_res_base, feat_imp_base = classify(train_control.copy(),\n",
    "                                                             test_control.copy(),\n",
    "                                                             classifier = 'lgbm',\n",
    "                                                             cv = 3, \n",
    "                                                             param_grid = param_grid_lgbm,\n",
    "                                                             n_jobs = 1)\n",
    "\n",
    "for par, score in zip(search_res_base['params'], search_res_base['mean_test_score']) :\n",
    "    print(f\"Config: {par} -- score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_base.to_csv('log_test1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test two**: use of engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_log = {'clf__C': [0.0001, 0.0005]}\n",
    "param_grid_tree = {'clf__max_depth': [5, 7, 10]}\n",
    "param_grid_rf = {'clf__n_estimators': [150], 'clf__max_depth': [7, 10], 'clf__n_jobs' : [-1]}\n",
    "param_grid_lgbm = {'clf__objective': ['binary'],\n",
    "                   'clf__metric': ['auc'],\n",
    "                   'clf__n_estimators': [150], \n",
    "                   'clf__max_depth': [7, 10]}\n",
    "\n",
    "predictions, search_res, feat_imp = classify(train.copy(),\n",
    "                                             test.copy(),\n",
    "                                             classifier = 'lgbm',\n",
    "                                             cv = 3, \n",
    "                                             param_grid = param_grid_lgbm,\n",
    "                                             n_jobs = 1)\n",
    "\n",
    "for par, score in zip(search_res['params'], search_res['mean_test_score']) :\n",
    "    print(f\"Config: {par} -- score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('log_test2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test three**: use of engineered features plus removal of collinear features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_log = {'clf__C': [0.0001, 0.0005]}\n",
    "param_grid_tree = {'clf__max_depth': [5, 7, 10]}\n",
    "param_grid_rf = {'clf__n_estimators': [150], 'clf__max_depth': [7, 10], 'clf__n_jobs' : [-1]}\n",
    "param_grid_lgbm = {'clf__objective': ['binary'],\n",
    "                   'clf__metric': ['auc'],\n",
    "                   'clf__n_estimators': [150], \n",
    "                   'clf__max_depth': [7, 10]}\n",
    "\n",
    "predictions_rem, search_res_rem, feat_imp_rem = classify(train_corrs_removed.copy(),\n",
    "                                             test_corrs_removed.copy(),\n",
    "                                             classifier = 'lgbm',\n",
    "                                             cv = 3, \n",
    "                                             param_grid = param_grid_lgbm,\n",
    "                                             n_jobs = 1)\n",
    "\n",
    "for par, score in zip(search_res_rem['params'], search_res_rem['mean_test_score']) :\n",
    "    print(f\"Config: {par} -- score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rem.to_csv('log_test3.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's submit the three CSVs on Kaggle and see if our feature engineering helped...\n",
    "\n",
    "Finally, let's have a look at the feature importance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the feature importances for the default features\n",
    "feature_importances_base = plot_feature_importances(feat_imp_base)\n",
    "feature_importances = plot_feature_importances(feat_imp)\n",
    "feature_importances_rem = plot_feature_importances(feat_imp_rem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
